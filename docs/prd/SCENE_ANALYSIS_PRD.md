# Re:View - ì”¬ ë¶„ì„ ì¤‘ì‹¬ PRD

**Version**: 1.0
**Focus**: Scene-based Video Analysis & Review
**Last Updated**: 2025-11-03

---

## ğŸ¬ ì œí’ˆ ì¬ì •ì˜

### ìƒˆë¡œìš´ ë¹„ì „
"ì˜ìƒì˜ ëª¨ë“  ì”¬ì„ ì´í•´í•˜ê³  ë¦¬ë·°ë¥¼ ìë™í™”í•˜ëŠ” AI í”Œë«í¼"

### í•µì‹¬ ê°€ì¹˜
- **ì”¬ ë‹¨ìœ„ ë¶„ì„**: ì˜ë¯¸ ìˆëŠ” ì˜ìƒ ë‹¨ìœ„ë¡œ ë¶„í•´
- **ë‚´ìš© ì´í•´**: ê° ì”¬ì´ ë‹´ê³  ìˆëŠ” ì •ë³´ íŒŒì•…
- **ë¦¬ë·° ìë™í™”**: ì”¬ë³„ í’ˆì§ˆ í‰ê°€ ë° ê°œì„ ì  ì œì‹œ

---

## ğŸ¯ ì”¬ ë¶„ì„ ê³„ì¸µ êµ¬ì¡°

```
Level 1: ì”¬ ê°ì§€ (Detection)
    â†“
Level 2: ì”¬ ë¶„ë¥˜ (Classification)
    â†“
Level 3: ì”¬ ì´í•´ (Understanding)
    â†“
Level 4: ì”¬ í‰ê°€ (Evaluation)
```

---

## ğŸ“‹ MVP - ì”¬ ê°ì§€ ë° ê¸°ë³¸ ë¶„ì„ (4ì£¼)

### ëª©í‘œ
"ì˜ìƒì„ ì”¬ ë‹¨ìœ„ë¡œ ìë™ ë¶„í• í•˜ê³  ê¸°ë³¸ ì •ë³´ ì œê³µ"

### í•µì‹¬ ê¸°ëŠ¥

#### 1. ì”¬ ê²½ê³„ ê°ì§€ (Scene Boundary Detection)

```python
class SceneDetector:
    """ì”¬ ì „í™˜ì  ê°ì§€"""

    def detect_hard_cuts(self, video_path):
        """ê¸‰ê²©í•œ ì „í™˜ ê°ì§€"""
        # ì•Œê³ ë¦¬ì¦˜:
        # 1. í”„ë ˆì„ ê°„ í”½ì…€ ì°¨ì´ ê³„ì‚°
        # 2. íˆìŠ¤í† ê·¸ë¨ ì°¨ì´ ë¶„ì„
        # 3. ì—£ì§€ ë³€í™”ìœ¨ ì¸¡ì •
        # 4. ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì”¬ ì „í™˜

        thresholds = {
            'pixel_diff': 0.4,
            'histogram_diff': 0.3,
            'edge_diff': 0.35
        }
        return scene_boundaries

    def detect_gradual_transitions(self, video_path):
        """ì ì§„ì  ì „í™˜ ê°ì§€ (Fade, Dissolve)"""
        # ë‹¤ì¤‘ í”„ë ˆì„ ë¶„ì„
        # ë³€í™” íŒ¨í„´ ì¸ì‹
        pass
```

#### 2. ì”¬ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

```yaml
ì”¬ ì •ë³´:
  - scene_id: ê³ ìœ  ì‹ë³„ì
  - start_time: ì‹œì‘ ì‹œê°„ (HH:MM:SS.fff)
  - end_time: ì¢…ë£Œ ì‹œê°„
  - duration: ì”¬ ê¸¸ì´
  - frame_count: í”„ë ˆì„ ìˆ˜
  - thumbnail: ëŒ€í‘œ ì´ë¯¸ì§€
  - transition_type: cut/fade/dissolve
```

#### 3. ê¸°ë³¸ ì”¬ íŠ¹ì§• ë¶„ì„

```yaml
ì‹œê°ì  íŠ¹ì§•:
  - dominant_color: ì£¼ìš” ìƒ‰ìƒ
  - brightness: ë°ê¸° í‰ê· 
  - contrast: ëŒ€ë¹„ ìˆ˜ì¤€
  - motion_level: ì›€ì§ì„ ì •ë„ (static/slow/fast)

í†µê³„ ì •ë³´:
  - total_scenes: ì „ì²´ ì”¬ ê°œìˆ˜
  - avg_scene_duration: í‰ê·  ì”¬ ê¸¸ì´
  - shortest/longest_scene: ìµœì†Œ/ìµœëŒ€ ê¸¸ì´
```

### MVP êµ¬í˜„ ì½”ë“œ ì˜ˆì‹œ

```python
# backend/app/scene_analyzer.py
import cv2
import numpy as np
from typing import List, Dict

class MVPSceneAnalyzer:
    def __init__(self, threshold=30.0):
        self.threshold = threshold
        self.min_scene_length = 10  # ìµœì†Œ 10í”„ë ˆì„

    def analyze_video(self, video_path: str) -> Dict:
        """MVP ì”¬ ë¶„ì„"""
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)

        scenes = []
        prev_frame = None
        scene_start = 0
        frame_idx = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            if prev_frame is not None:
                # í”„ë ˆì„ ì°¨ì´ ê³„ì‚°
                diff = self.calculate_frame_diff(prev_frame, frame)

                if diff > self.threshold:
                    # ì”¬ ì „í™˜ ê°ì§€
                    if frame_idx - scene_start > self.min_scene_length:
                        scenes.append({
                            'scene_id': len(scenes) + 1,
                            'start_frame': scene_start,
                            'end_frame': frame_idx,
                            'start_time': scene_start / fps,
                            'end_time': frame_idx / fps,
                            'duration': (frame_idx - scene_start) / fps,
                            'thumbnail': self.extract_thumbnail(
                                video_path,
                                (scene_start + frame_idx) // 2
                            )
                        })
                        scene_start = frame_idx

            prev_frame = frame
            frame_idx += 1

        cap.release()

        return {
            'scenes': scenes,
            'total_scenes': len(scenes),
            'total_duration': frame_idx / fps,
            'avg_scene_duration': np.mean([s['duration'] for s in scenes])
        }

    def calculate_frame_diff(self, frame1, frame2):
        """í”„ë ˆì„ ê°„ ì°¨ì´ ê³„ì‚°"""
        # íˆìŠ¤í† ê·¸ë¨ ì°¨ì´
        hist1 = cv2.calcHist([frame1], [0, 1, 2], None,
                            [32, 32, 32], [0, 256, 0, 256, 0, 256])
        hist2 = cv2.calcHist([frame2], [0, 1, 2], None,
                            [32, 32, 32], [0, 256, 0, 256, 0, 256])

        hist_diff = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR)

        # ì—£ì§€ ì°¨ì´
        edges1 = cv2.Canny(cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY), 50, 150)
        edges2 = cv2.Canny(cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY), 50, 150)
        edge_diff = np.mean(np.abs(edges1.astype(float) - edges2.astype(float)))

        # ì¢…í•© ì ìˆ˜
        return hist_diff * 0.7 + edge_diff * 0.3
```

### MVP UI êµ¬ì„±

```jsx
// frontend/src/components/SceneTimeline.jsx
import React from 'react';
import { Timeline, Card, Image } from 'antd';

function SceneTimeline({ scenes }) {
    return (
        <div className="scene-timeline">
            <h2>ì”¬ ë¶„ì„ ê²°ê³¼: {scenes.length}ê°œ ì”¬ ê°ì§€</h2>

            <div className="scene-grid">
                {scenes.map(scene => (
                    <Card
                        key={scene.scene_id}
                        hoverable
                        cover={<Image src={scene.thumbnail} />}
                        onClick={() => seekToScene(scene.start_time)}
                    >
                        <Card.Meta
                            title={`Scene ${scene.scene_id}`}
                            description={`${formatTime(scene.start_time)} - ${formatTime(scene.end_time)}`}
                        />
                        <p>ê¸¸ì´: {scene.duration.toFixed(1)}ì´ˆ</p>
                    </Card>
                ))}
            </div>

            <Timeline className="scene-timeline-view">
                {scenes.map(scene => (
                    <Timeline.Item key={scene.scene_id}>
                        <p>Scene {scene.scene_id}</p>
                        <p>{formatTime(scene.start_time)}</p>
                    </Timeline.Item>
                ))}
            </Timeline>
        </div>
    );
}
```

---

## ğŸš€ Pro - ì”¬ ë‚´ìš© ë¶„ì„ (8ì£¼)

### ì¶”ê°€ ê¸°ëŠ¥

#### 1. ìƒ· íƒ€ì… ë¶„ë¥˜

```python
class ShotClassifier:
    """ìƒ· í¬ê¸° ë° ì•µê¸€ ë¶„ë¥˜"""

    shot_types = {
        'EWS': 'Extreme Wide Shot',  # ì „ê²½
        'WS': 'Wide Shot',           # ë¡±ìƒ·
        'MS': 'Medium Shot',         # ë¯¸ë””ì—„ìƒ·
        'CU': 'Close Up',            # í´ë¡œì¦ˆì—…
        'ECU': 'Extreme Close Up'    # ìµìŠ¤íŠ¸ë¦¼ í´ë¡œì¦ˆì—…
    }

    def classify_shot(self, frame):
        # ì–¼êµ´ ê°ì§€ ê¸°ë°˜ ë¶„ë¥˜
        faces = self.detect_faces(frame)
        if not faces:
            return 'WS'  # ì–¼êµ´ ì—†ìœ¼ë©´ ì™€ì´ë“œìƒ·

        # ì–¼êµ´ í¬ê¸°ë¡œ ìƒ· íƒ€ì… ê²°ì •
        face_area_ratio = self.calculate_face_ratio(faces, frame)

        if face_area_ratio > 0.5:
            return 'ECU'
        elif face_area_ratio > 0.3:
            return 'CU'
        elif face_area_ratio > 0.1:
            return 'MS'
        else:
            return 'WS'
```

#### 2. ì”¬ ë‚´ìš© ì´í•´

```python
class SceneContentAnalyzer:
    """ì”¬ ë‚´ìš© AI ë¶„ì„"""

    def __init__(self):
        self.yolo = YOLO('yolov8x.pt')  # ê°ì²´ ê°ì§€
        self.whisper = whisper.load_model('large')  # ìŒì„± ì¸ì‹

    def analyze_scene_content(self, scene_frames, audio_segment):
        """ì”¬ì˜ ë‚´ìš© ë¶„ì„"""

        # ì‹œê°ì  ìš”ì†Œ
        objects = self.detect_objects(scene_frames)
        people_count = self.count_people(scene_frames)
        activities = self.detect_activities(scene_frames)

        # ì˜¤ë””ì˜¤ ìš”ì†Œ
        transcript = self.transcribe_audio(audio_segment)
        speaker_count = self.count_speakers(audio_segment)
        music_detected = self.detect_music(audio_segment)

        # í…ìŠ¤íŠ¸/ê·¸ë˜í”½
        on_screen_text = self.extract_text(scene_frames)
        graphics = self.detect_graphics(scene_frames)

        return {
            'visual': {
                'objects': objects,
                'people': people_count,
                'activities': activities
            },
            'audio': {
                'transcript': transcript,
                'speakers': speaker_count,
                'has_music': music_detected
            },
            'graphics': {
                'text': on_screen_text,
                'overlays': graphics
            }
        }
```

#### 3. ì”¬ ë¶„ë¥˜ ë° íƒœê¹…

```yaml
ì”¬ ì¹´í…Œê³ ë¦¬:
  - Interview: ì¸í„°ë·°/ëŒ€ë‹´
  - Action: ì•¡ì…˜/ìŠ¤í¬ì¸ 
  - Landscape: í’ê²½/ë°°ê²½
  - Graphics: ê·¸ë˜í”½/íƒ€ì´í‹€
  - Transition: ì „í™˜ íš¨ê³¼

ìë™ íƒœê·¸:
  - #outdoor #daytime #crowded
  - #studio #interview #two-shot
  - #montage #fast-paced #music
```

---

## ğŸ§  Enterprise - ì§€ëŠ¥í˜• ì”¬ ë¶„ì„ (12ì£¼)

### ê³ ê¸‰ ê¸°ëŠ¥

#### 1. ìŠ¤í† ë¦¬ í”Œë¡œìš° ë¶„ì„

```python
class StoryFlowAnalyzer:
    """ì„œì‚¬ êµ¬ì¡° ë¶„ì„"""

    def analyze_narrative_structure(self, scenes):
        """3ë§‰ êµ¬ì¡° ë¶„ì„"""

        # ë„ì…ë¶€ (Setup)
        setup_scenes = self.identify_setup(scenes[:len(scenes)//3])

        # ì „ê°œë¶€ (Confrontation)
        confrontation = self.identify_confrontation(
            scenes[len(scenes)//3:2*len(scenes)//3]
        )

        # ê²°ë§ë¶€ (Resolution)
        resolution = self.identify_resolution(scenes[2*len(scenes)//3:])

        # í´ë¼ì´ë§¥ìŠ¤ ê°ì§€
        climax = self.detect_climax(scenes)

        return {
            'structure': '3-act',
            'setup': setup_scenes,
            'confrontation': confrontation,
            'resolution': resolution,
            'climax': climax,
            'pacing': self.analyze_pacing(scenes)
        }
```

#### 2. í¸ì§‘ í’ˆì§ˆ í‰ê°€

```python
class EditingQualityEvaluator:
    """í¸ì§‘ í’ˆì§ˆ ìë™ í‰ê°€"""

    def evaluate_editing(self, scenes):
        scores = {
            'continuity': self.check_continuity(scenes),  # ì—°ì†ì„±
            'rhythm': self.analyze_rhythm(scenes),         # ë¦¬ë“¬
            'transitions': self.evaluate_transitions(scenes), # ì „í™˜
            'pacing': self.evaluate_pacing(scenes),        # í˜ì´ì‹±
            'coherence': self.check_coherence(scenes)      # ì¼ê´€ì„±
        }

        overall_score = np.mean(list(scores.values()))

        recommendations = self.generate_recommendations(scores)

        return {
            'scores': scores,
            'overall': overall_score,
            'grade': self.score_to_grade(overall_score),
            'recommendations': recommendations
        }
```

#### 3. AI ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ ìƒì„±

```python
class HighlightGenerator:
    """ìë™ í•˜ì´ë¼ì´íŠ¸ ìƒì„±"""

    def generate_highlights(self, scenes, target_duration=60):
        """1ë¶„ í•˜ì´ë¼ì´íŠ¸ ìë™ ìƒì„±"""

        # ì”¬ ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
        scene_scores = []
        for scene in scenes:
            score = self.calculate_importance(scene)
            scene_scores.append((scene, score))

        # ìƒìœ„ ì”¬ ì„ íƒ
        scene_scores.sort(key=lambda x: x[1], reverse=True)

        selected_scenes = []
        total_duration = 0

        for scene, score in scene_scores:
            if total_duration + scene['duration'] <= target_duration:
                selected_scenes.append(scene)
                total_duration += scene['duration']

        # ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬
        selected_scenes.sort(key=lambda x: x['start_time'])

        return {
            'scenes': selected_scenes,
            'duration': total_duration,
            'score': np.mean([s[1] for s in scene_scores[:len(selected_scenes)]])
        }
```

---

## ğŸ“Š ë‹¨ê³„ë³„ ì •í™•ë„ ë° ì„±ëŠ¥ ëª©í‘œ

| ë‹¨ê³„ | ì”¬ ê°ì§€ ì •í™•ë„ | ì²˜ë¦¬ ì†ë„ | ë¶„ì„ ê¹Šì´ |
|------|---------------|-----------|-----------|
| **MVP** | 85% (Hard Cut) | 1x ì‹¤ì‹œê°„ | ê¸°ë³¸ ë©”íƒ€ë°ì´í„° |
| **Pro** | 95% (ëª¨ë“  ì „í™˜) | 5x ì‹¤ì‹œê°„ (GPU) | ë‚´ìš© ì´í•´ |
| **Enterprise** | 99% | 10x ì‹¤ì‹œê°„ | ì˜ë¯¸ ë¶„ì„ |

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ ì§„í™”

### MVP (CPU ê¸°ë°˜)
```yaml
Core:
  - Python 3.11
  - OpenCV 4.8
  - NumPy
  - FFmpeg

Storage:
  - SQLite
  - Local File System
```

### Pro (GPU ê°€ì†)
```yaml
ì¶”ê°€:
  - CUDA 11.8
  - PyTorch 2.0
  - YOLO v8
  - Whisper
  - Face Recognition

Optimization:
  - GPU Processing
  - Parallel Analysis
  - Redis Cache
```

### Enterprise (AI í†µí•©)
```yaml
ì¶”ê°€:
  - Transformers
  - Video-LLM
  - Multi-modal Models
  - Knowledge Graph

Infrastructure:
  - Kubernetes
  - Distributed Processing
  - Cloud Storage
```

---

## ğŸ’¡ í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ

### ë°©ì†¡ ë¦¬ë·° íŠ¹í™”

1. **í”„ë¡œë•ì…˜ ì¤‘ì‹¬ ë¶„ì„**
   - PD/TD ê´€ì  ì”¬ ë¶„ë¥˜
   - ë°©ì†¡ í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸
   - í¸ì§‘ì  ìë™ ë§ˆí‚¹

2. **ì‹¤ì‹œê°„ í”¼ë“œë°±**
   - ë¼ì´ë¸Œ ì¤‘ ì”¬ ì „í™˜ ì•Œë¦¼
   - ì‹¤ì‹œê°„ í’ˆì§ˆ ì§€í‘œ
   - ì¦‰ê°ì  ê°œì„  ì œì•ˆ

3. **í•™ìŠµ ê¸°ë°˜ ê°œì„ **
   - ê³¼ê±° ë°©ì†¡ íŒ¨í„´ í•™ìŠµ
   - íŒ€ë³„ ìŠ¤íƒ€ì¼ ì¸ì‹
   - ë§ì¶¤í˜• ì œì•ˆ

---

## ğŸ¯ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### MVP: ê¸°ë³¸ ì”¬ ë¶„ì„
```
1. ì˜ìƒ ì—…ë¡œë“œ
2. ìë™ ì”¬ ë¶„í•  (2ë¶„ ì†Œìš”/1ì‹œê°„ ì˜ìƒ)
3. ì”¬ íƒ€ì„ë¼ì¸ ìƒì„±
4. ì”¬ë³„ ì¸ë„¤ì¼ ë° ê¸°ë³¸ ì •ë³´ ì œê³µ
5. CSV ë¦¬í¬íŠ¸ ì¶œë ¥
```

### Pro: ë‚´ìš© ê¸°ë°˜ ë¦¬ë·°
```
1. ì˜ìƒ ì—…ë¡œë“œ
2. GPU ê°€ì† ë¶„ì„ (30ì´ˆ ì†Œìš”/1ì‹œê°„ ì˜ìƒ)
3. ì”¬ë³„ ë‚´ìš© íƒœê¹…
4. ê°ì²´/ì–¼êµ´/ìŒì„± ì¸ì‹
5. ì”¬ í’ˆì§ˆ ì ìˆ˜ ì œê³µ
6. ê°œì„  ì œì•ˆ ìƒì„±
```

### Enterprise: ì™„ì „ ìë™í™”
```
1. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
2. ë¼ì´ë¸Œ ì”¬ ë¶„ì„
3. AI ê¸°ë°˜ í•˜ì´ë¼ì´íŠ¸ ìƒì„±
4. ìë™ í¸ì§‘ ì œì•ˆ
5. ë‹¤ìŒ ë°©ì†¡ ì˜ˆì¸¡ ë° ì¶”ì²œ
```

---

## ğŸ“ˆ ROI ë¶„ì„

### ì‹œê°„ ì ˆê°
- **í˜„ì¬**: 1ì‹œê°„ ì˜ìƒ â†’ 8ì‹œê°„ ìˆ˜ë™ ë¦¬ë·°
- **MVP**: 1ì‹œê°„ ì˜ìƒ â†’ 2ë¶„ ì²˜ë¦¬ + 30ë¶„ ë¦¬ë·°
- **Pro**: 1ì‹œê°„ ì˜ìƒ â†’ 30ì´ˆ ì²˜ë¦¬ + 10ë¶„ ë¦¬ë·°
- **Enterprise**: ì‹¤ì‹œê°„ ì²˜ë¦¬ + ìë™ ë¦¬í¬íŠ¸

### í’ˆì§ˆ í–¥ìƒ
- **ì”¬ ëˆ„ë½**: 100% â†’ 15% â†’ 5% â†’ 1%
- **í¸ì§‘ ì˜¤ë¥˜**: ìˆ˜ë™ ë°œê²¬ â†’ 85% ìë™ â†’ 95% â†’ 99%
- **ê°œì„  ì†ë„**: ë‹¤ìŒ ë°©ì†¡ â†’ ì¦‰ì‹œ â†’ ì‹¤ì‹œê°„

---

## ğŸš¦ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Week 1-2: ì”¬ ê°ì§€ ì—”ì§„
```python
# í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- [ ] í”„ë ˆì„ ì°¨ì´ ê³„ì‚°
- [ ] íˆìŠ¤í† ê·¸ë¨ ë¶„ì„
- [ ] ì”¬ ê²½ê³„ ê²°ì •
- [ ] ì¸ë„¤ì¼ ì¶”ì¶œ
```

### Week 3: UI/UX
```javascript
// í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„
- [ ] ë¹„ë””ì˜¤ í”Œë ˆì´ì–´
- [ ] ì”¬ íƒ€ì„ë¼ì¸
- [ ] ì¸ë„¤ì¼ ê·¸ë¦¬ë“œ
- [ ] ì”¬ ì í”„ ë„¤ë¹„ê²Œì´ì…˜
```

### Week 4: í†µí•© ë° ìµœì í™”
```yaml
- [ ] API ì—°ê²°
- [ ] ì„±ëŠ¥ ìµœì í™”
- [ ] í…ŒìŠ¤íŠ¸ ë° ë²„ê·¸ ìˆ˜ì •
- [ ] ë¬¸ì„œí™”
```

---

## ğŸ¬ ê²°ë¡ 

ì”¬ ë¶„ì„ ì¤‘ì‹¬ MVPëŠ”:
1. **ê¸°ìˆ ì ìœ¼ë¡œ ì‹¤í˜„ ê°€ëŠ¥** (ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜)
2. **ì¦‰ê°ì  ê°€ì¹˜ ì œê³µ** (ìˆ˜ë™ ì‘ì—… ìë™í™”)
3. **í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°** (MVP â†’ Pro â†’ Enterprise)
4. **ëª…í™•í•œ ì°¨ë³„í™”** (ë°©ì†¡ ë¦¬ë·° íŠ¹í™”)

**ê·€í•˜ì˜ ì‹œìŠ¤í…œ(Ryzen 9 + RTX 3090)ì—ì„œëŠ” Pro ìˆ˜ì¤€ê¹Œì§€ ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤!**

---

*ì”¬ ë¶„ì„ì´ ì˜ìƒ ë¦¬ë·°ì˜ í•µì‹¬ì…ë‹ˆë‹¤.*